# Effect-of-Tokenization-on-Downstream-Task-using-M-Bert
>> Study of Tokenization for different Multilingual Dataset with M-Bert and X-LMR. >> Define the different matrices to get the comparative pictorial representation. >> Not getting proper tokenization of the Indian languages in comparison of English language. >> This will result into poor embedding. >> Finally all this will affect to downstream tasks. >> This issue will resolve by adding some words into vocabulary and also improvement of model. >> So translated words which has poor tokenization . >> Replace those translated words in original data set to increase accuracy of pretrained models.
